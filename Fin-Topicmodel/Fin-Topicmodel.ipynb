{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "os.chdir(\"Fin-Topicmodel\")\n",
    "csv_path='dataset_22-24_report_title.csv'\n",
    "# csv_path='report_titles_dataset/dataset_22-24_report_title.csv'\n",
    "df_loaded = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "titles = df_loaded['metadata'].tolist()\n",
    "date_strs = df_loaded['date_str'].tolist()\n",
    "for i, date_str in enumerate(date_strs):\n",
    "    date_strs[i] = str(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_path=\"valuesimplex-ai-lab/Fin-Retriever-base\"   #Finretriever\n",
    "embedding_model = SentenceTransformer(embedding_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model_path)\n",
    "titles_embeddings = embedding_model.encode(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 创建UMAP降维模型\n",
    "umap_model = UMAP(\n",
    "  n_neighbors=15,\n",
    "  n_components=32,    #降维维度\n",
    "  min_dist=0.0,\n",
    "  metric='cosine',\n",
    "  random_state=22  # ⚠️ 防止随机 https://maartengr.github.io/BERTopic/faq.html\n",
    ")\n",
    "\n",
    "# 3. 创建HDBSCAN聚类模型\n",
    "# 如果要减少离群值，可以减小下面两个参数min_cluster_size min_samples\n",
    "# https://hdbscan.readthedocs.io/en/latest/faq.html\n",
    "hdbscan_model = HDBSCAN(\n",
    "  min_cluster_size=2,\n",
    "  min_samples=1,    #默认=min_cluster_size\n",
    "  metric='euclidean'\n",
    ")\n",
    "\n",
    "from merge_tokenizer import *\n",
    "\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # 去除换行符并生成停用词列表\n",
    "        stopwords = [line.strip() for line in file]\n",
    "    return stopwords\n",
    "# 加载停用词文件\n",
    "stop_words = load_stopwords(\"stopwords_cn.txt\")\n",
    "\n",
    "# vectorizer = CountVectorizer(tokenizer=chinese_tokenizer,stop_words=stop_words)\n",
    "vectorizer = CountVectorizer(tokenizer=merge_tokenizers,stop_words=stop_words)\n",
    "\n",
    "# 6. 正式创建BERTopic模型\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,\n",
    "  vectorizer_model=vectorizer,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model, \n",
    "#   min_topic_size=2 ,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chinese_tokenizer(\"绿水青山就是金山银山\"))\n",
    "print(chinese_tokenizer(\"金山办公\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge_tokenizers(\"绿水青山就是金山银山\"))\n",
    "print(merge_tokenizers(\"金山办公\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看主题\n",
    "# topics, probs = topic_model.fit_transform(titles)\n",
    "topics, probs = topic_model.fit_transform(titles, embeddings=np.array(titles_embeddings)) #传入训练好的词向量\n",
    "outfilename=\"berttopic_titles_report_new_finretriever_large_embedder_merge_tokenizer\"\n",
    "\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.to_csv(outfilename+'_topic_info_raw.csv', index=False)\n",
    "topic_docs = topic_model.get_document_info(titles)\n",
    "topic_docs.to_csv(outfilename+'_topic_docs_raw.csv')\n",
    "\n",
    "import copy\n",
    "# 创建 topic_model 的深拷贝\n",
    "topic_model2 = copy.deepcopy(topic_model)\n",
    "#Reduce outliers(标签为-1的数据)\n",
    "new_topics = topic_model2.reduce_outliers(titles, topics, threshold=0.4)   # 默认threshold=0，越大没有分配标签的-1数据就越多\n",
    "# 官方提供四种策略 https://maartengr.github.io/BERTopic/getting_started/outlier_reduction/outlier_reduction.html#exploration\n",
    "\n",
    "topic_model2.update_topics(titles, topics=new_topics,vectorizer_model=vectorizer)\n",
    "topic_info_new = topic_model2.get_topic_info()\n",
    "topic_info_new.to_csv(outfilename+'_topic_info_reduced_outliers.csv', index=False)\n",
    "topic_docs = topic_model2.get_document_info(titles)\n",
    "topic_docs.to_csv(outfilename+'_topic_docs_reduced_outliers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查看文档的主题分布\n",
    "# print(topic_model.get_topics())\n",
    "# print(\"文档主题分布：\")\n",
    "# print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存聚类质量评估结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_cluster_quality import *\n",
    "reduced_embeddings = umap_model.fit_transform(titles_embeddings)\n",
    "average_silhouette, ch_score,db_score ,td_value = evaluate_clustering(outfilename+'_topic_docs_raw.csv', reduced_embeddings)\n",
    "# average_silhouette, ch_score,db_score ,td_value = evaluate_clustering(outfilename+'_topic_docs_reduced_outliers.csv', reduced_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(title=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 层次聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model2.hierarchical_topics(titles)\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "\n",
    "hierarchical_topics_path = outfilename+\"_hierarchical_topics.csv\"  # 保存分层主题路径\n",
    "tree_path = outfilename+\"_hierarchical_tree.txt\"  # 保存主题树路径\n",
    "hierarchical_topics.to_csv(hierarchical_topics_path)\n",
    "    # 保存 tree 为文本文件\n",
    "with open(tree_path, 'w', encoding='utf-8') as tree_file:\n",
    "    tree_file.write(tree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinBERT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
